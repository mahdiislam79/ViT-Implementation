{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8xjj9BV2Jfmh3W9bn5nYi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahdiislam79/ViT-Implementation/blob/main/ViT_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 Getting Setup"
      ],
      "metadata": {
        "id": "GPYh7H-R1vDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")"
      ],
      "metadata": {
        "id": "20FPQBNt11-M",
        "outputId": "ef63980b-2c42-495d-ce93-6d1ffae29ad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 1.13.1+cu116\n",
            "torchvision version: 0.14.1+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# continue with regular imports \n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  print(f\"[INFO] Couldn't find torchinfo. Installing it.\")\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary\n"
      ],
      "metadata": {
        "id": "7ukryvne2k0p",
        "outputId": "84d3a729-b316-4440-8501-cec126d5504f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo. Installing it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !mv pytorch-deep-learning/helper_functions.py . # get the helper_functions.py script\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves"
      ],
      "metadata": {
        "id": "fu4nwK5l3_0G",
        "outputId": "8d811317-ac50-47f2-c6e4-5983f704e10d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 3426, done.\u001b[K\n",
            "remote: Counting objects: 100% (124/124), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 3426 (delta 52), reused 100 (delta 44), pack-reused 3302\u001b[K\n",
            "Receiving objects: 100% (3426/3426), 643.49 MiB | 16.50 MiB/s, done.\n",
            "Resolving deltas: 100% (1959/1959), done.\n",
            "Updating files: 100% (222/222), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "KQk_Ne-X4kh0",
        "outputId": "ead0fa61-574a-4526-ba92-82650e96d7ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Get Data"
      ],
      "metadata": {
        "id": "Bi1ZSqiX5ci1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pizza, steak, sushi images from GitHub\n",
        "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                           destination=\"pizza_steak_sushi\")\n",
        "image_path"
      ],
      "metadata": {
        "id": "pV7A57Kx5HiY",
        "outputId": "8498f038-4f8c-4612-9eb3-f12b68b61e40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Did not find data/pizza_steak_sushi directory, creating one...\n",
            "[INFO] Downloading pizza_steak_sushi.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip...\n",
            "[INFO] Unzipping pizza_steak_sushi.zip data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup directory paths to train and test images\n",
        "train_dir = image_path / 'train'\n",
        "test_dir = image_path / 'test'"
      ],
      "metadata": {
        "id": "O2LYEv5E5nS7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 2. Create Datasets and DataLoaders\n",
        "\n",
        "Now we've got some data, let's now turn it into `DataLoader`'s.\n",
        "\n",
        "To do so we can use the `create_dataloaders()` function in [`data_setup.py`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/data_setup.py).\n",
        "\n",
        "First, we'll create a transform to prepare our images.\n",
        "\n",
        "This where one of the first references to the ViT paper will come in.\n",
        "\n",
        "In Table 3, the training resolution is mentioned as being 224 (height=224, width=224). \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/08-vit-paper-image-size-and-batch-size.png\" width=900 alt=\"Table 3 from the Vision Transformer paper showing the image size and batch size\"/>\n",
        "\n",
        "*You can often find various hyperparameter settings listed in a table. In this case we're still preparing our data, so we're mainly concerned with things like image size and batch size. Source: Table 3 in [ViT paper](https://arxiv.org/abs/2010.11929).*"
      ],
      "metadata": {
        "id": "PRfLfQzu6msI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1gVNizPq6G_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}